{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest: Classification by Automation Condition (By Participant Sampling)\n",
    "- Prediction of automation usage using all features and the top 20\n",
    "- We train and test by automation condition\n",
    "    - Grouping the data from all participants in a condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os as os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose if running on Agave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGAVE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Choose automation condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_condition  = 3\n",
    "conditions = ['SH','SL','FH','FL','ALL']\n",
    "cond = conditions[choose_condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "if(AGAVE==True):\n",
    "    files_path = '../../../NewFeatures/' + cond             # Agave\n",
    "else:\n",
    "    files_path = '../../../features_data_risk/' + cond      # Local\n",
    "\n",
    "all_files = glob.glob(os.path.join(files_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that offer extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that offer extra information (they're basically the same as boolAuto)\n",
    "features_extra = ['boolHand','boolTake','brakeOshp','sumAuto','sumHand','sumTake','sumTogg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that are related to the operator's actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions\n",
    "features_internal = ['accAngOshpX','accAngOshpY','accAngOshpZ','accLinOshpX',\n",
    "\t\t\t\t\t'accLinOshpY','accLinOshpZ','boolButnA','boolButnB',\n",
    "\t\t\t\t\t'boolViolButn','boolViolLane','boolViolLead','boolViolPeds',\n",
    "\t\t\t\t\t'boolViolRang','boolViolTraf','boolViolVehs',\n",
    "\t\t\t\t\t'oriOshpX','oriOshpY','oriOshpZ','psnOshpLane','psnOshpLaneAbs',\n",
    "\t\t\t\t\t'psnOshpLaneLft','psnOshpX','psnOshpY','psnOshpZ',\n",
    "\t\t\t\t\t'steerOshp','sumViolButn','sumViolLane','sumViolLead','sumViolPeds',\n",
    "\t\t\t\t\t'sumViolRang','sumViolTraf','sumViolVehs','throtOshp','timeReact',\n",
    "\t\t\t\t\t'velAngOshpX','velAngOshpY','velAngOshpZ','velLinOshp','velLinOshpLane',\n",
    "\t\t\t\t\t'velLinOshpLaneAbs','velLinOshpLaneLft','velLinOshpRang','velLinOshpX',\n",
    "\t\t\t\t\t'velLinOshpY','velLinOshpZ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "# Assign features from current time-step to future use of automation,\n",
    "# The idea is to predict future use of automation based on current behavior\n",
    "delay = 1/60            # How much time in advance we want to predict automation usage (in seconds)\n",
    "h = (int)(delay*60 - 1) # Turn the time into index (Considering a sampling rate of 60 Hz)\n",
    "data_list = []\n",
    "for file in all_files:\n",
    "    data_participant = pd.read_csv(file)\n",
    "    data_participant.insert(0,\"time\",[(i*1/60) for i in range(0,data_participant.shape[0])],True)\n",
    "    data_auto = data_participant['boolAuto']\n",
    "    data_auto = np.array(data_auto.iloc[h:])\n",
    "    data_participant = data_participant.drop('boolAuto', axis=1)\n",
    "    data_participant = data_participant.head(data_participant.shape[0]-h)\n",
    "    data_participant.insert(data_participant.shape[1],\"boolAuto\",data_auto,True)\n",
    "    data_list.append(data_participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH_feats = ['psnOshpRang'    ,\n",
    "'score'          ,\n",
    "'velLinOshpX'    ,\n",
    "'velLinOshp'     ,\n",
    "'rrisk'          ,\n",
    "'sumViolLane'    ,\n",
    "'velLinLead'     ,\n",
    "'throtOshp'      ,\n",
    "'sumViolRang'    ,\n",
    "'odomRoad'       ,\n",
    "'velLinOshpRang' ,\n",
    "'sumViolPeds'    ,\n",
    "'ttcLead'        ,\n",
    "'sumViolButn'    ,\n",
    "'accLinOshpX'    ,\n",
    "'psnTrafPrxY'    ,\n",
    "'psnTrafPrxX'    ,\n",
    "'boolStatRang'   ,\n",
    "'oriTrafPrxZ'    ,\n",
    "'oriOshpY'       ]\n",
    "\n",
    "SL_feats = ['psnOshpRang'    ,\n",
    "'rrisk'          ,\n",
    "'sumViolAwrd'    ,\n",
    "'velLinOshp'     ,\n",
    "'throtOshp'      ,\n",
    "'velLinOshpX'    ,\n",
    "'sumViolRang'    ,\n",
    "'score'          ,\n",
    "'accLinOshpX'    ,\n",
    "'sumViolButn'    ,\n",
    "'oriOshpY'       ,\n",
    "'velLinLead'     ,\n",
    "'odomRoad'       ,\n",
    "'sumViolLane'    ,\n",
    "'velLinOshpRang' ,\n",
    "'psnTrafPrxX'    ,\n",
    "'psnTrafPrxY'    ,\n",
    "'accAngOshpY'    ,\n",
    "'oriLeadZ'       ,\n",
    "'velAngOshpY'    ]\n",
    "\n",
    "FH_feats = ['velLinOshpX'    ,\n",
    "'psnOshpRang'    ,\n",
    "'score'          ,\n",
    "'rrisk'          ,\n",
    "'velLinOshp'     ,\n",
    "'throtOshp'      ,\n",
    "'sumViolRang'    ,\n",
    "'velLinLead'     ,\n",
    "'odomRoad'       ,\n",
    "'sumViolButn'    ,\n",
    "'sumViolLane'    ,\n",
    "'accLinOshpX'    ,\n",
    "'velLinOshpRang' ,\n",
    "'psnOshpLaneLft' ,\n",
    "'oriTrafPrxZ'    ,\n",
    "'velAngLeadZAbs' ,\n",
    "'psnTrafPrxX'    ,\n",
    "'oriOshpY'       ,\n",
    "'psnTrafPrxY'    ,\n",
    "'oriOshpZ'       ]\n",
    "\n",
    "FL_feats = ['psnOshpRang' ,\n",
    "'sumViolAwrd' ,\n",
    "'velLinOshpX' ,\n",
    "'rrisk'       ,\n",
    "'throtOshp'   ,\n",
    "'velLinOshp'  ,\n",
    "'sumViolLane' ,\n",
    "'score'       ,\n",
    "'accLinOshpX' ,\n",
    "'odomRoad'    ,\n",
    "'sumViolRang' ,\n",
    "'oriTrafPrxZ' ,\n",
    "'sumViolButn' ,\n",
    "'psnTrafPrxX' ,\n",
    "'velLinLead'  ,\n",
    "'sumViolPeds' ,\n",
    "'psnLeadY'    ,\n",
    "'timeReact'   ,\n",
    "'psnTrafPrxY' ,\n",
    "'psnRoadY'    ]\n",
    "\n",
    "top_features_all = [SH_feats,SL_feats,FH_feats,FL_feats]\n",
    "top_feat_cond = top_features_all[choose_condition]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance results\n",
    "data_scores = {'Train_Acc':[],'Train_BalAcc':[],'Train_Prec':[],'Train_Rec':[],'Train_Spec':[],\n",
    "                'Train_AUC':[],'Test_Acc':[],'Test_BalAcc':[],'Test_Prec':[],'Test_Rec':[],\n",
    "                'Test_Spec':[],'Test_AUC':[]}\n",
    "perf_scores = pd.DataFrame(data=data_scores)\n",
    "# Save the ROC curve data\n",
    "data_roc = pd.DataFrame({'mean_fpr':[], 'tpr_1':[], 'tpr_2':[], 'tpr_3':[], 'tpr_4':[], \n",
    "                        'tpr_5':[]}) # 5 KFold\n",
    "# Save the best set of parameter for the model\n",
    "best_parameters = pd.DataFrame({'n_estimators':[], 'max_depth':[], 'max_features':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters fro random grid search\n",
    "SEED = 10\n",
    "n_estimators = [120, 890, 340, 890]\n",
    "max_depth = [242, 135, 457, 100]\n",
    "max_features = [15, 10, 10, 10]\n",
    "best_n_estim = n_estimators[choose_condition]\n",
    "best_max_depth = max_depth[choose_condition]\n",
    "best_max_features = max_features[choose_condition]\n",
    "\n",
    "# Indices of participants\n",
    "idx_part = list(range(0, 16))\n",
    "idx_label = [0]*8 + [1]*8\n",
    "\n",
    "# Create the k-fold\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# Create the classifier\n",
    "# classifier = RandomForestClassifier(n_estimators=best_n_estim, max_depth=best_max_depth,\n",
    "#                             max_features=best_max_features, n_jobs=-1)\n",
    "# classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "classifier = make_pipeline(StandardScaler(),LinearSVC())\n",
    "\n",
    "# Save performance metrics\n",
    "tprs = []; aucs = []; acc = []; acc_bal = []; prec = []; rec = []; spec = []; AUC_v = []\n",
    "acc_tr = []; acc_bal_tr = []; prec_tr = []; rec_tr = []; spec_tr = []; AUC_v_tr = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Apply cross-validation\n",
    "for _, (train, test) in enumerate(cv.split(idx_part,idx_label)):\n",
    "    train_list = [data_list[index] for index in train]\n",
    "    test_list = [data_list[index] for index in test]\n",
    "    # Read the data from the participants to be used for training and testing\n",
    "    df_data_train = pd.concat(train_list, ignore_index=True)\n",
    "    df_data_test = pd.concat(test_list, ignore_index=True)\n",
    "    # Delete the features that offer extra information from the dataset\n",
    "    df_data_train = df_data_train.drop(features_extra,axis = 1)\n",
    "    df_data_train = df_data_train.drop('time',axis=1)          # Drop the inserted time too\n",
    "    df_data_test = df_data_test.drop(features_extra,axis = 1)\n",
    "    df_data_test = df_data_test.drop('time',axis=1)\n",
    "    \n",
    "    # Check if running on Agave\n",
    "    if(AGAVE==True):\n",
    "        sample_train = df_data_train.sample(frac=1, random_state=SEED);\n",
    "        sample_test = df_data_test.sample(frac=1, random_state=SEED);\n",
    "    else:\n",
    "        sample_train = df_data_train.sample(frac=0.1, random_state=SEED);\n",
    "        sample_test = df_data_test.sample(frac=0.1, random_state=SEED);\n",
    "    \n",
    "    # Scale the data to a range [0,1]\n",
    "    idx_train = np.shape(sample_train)[0]\n",
    "    sample_comb = MinMaxScaler(copy=False).fit_transform(np.concatenate((sample_train[top_feat_cond].to_numpy(), \n",
    "                                    sample_test[top_feat_cond].to_numpy()), axis=0))\n",
    "    # Split scaled data into training and testing\n",
    "    X_train = sample_comb[0:idx_train]\n",
    "    y_train = sample_train['boolAuto']\n",
    "    X_test = sample_comb[idx_train:len(sample_comb)]\n",
    "    y_test = sample_test['boolAuto']\n",
    "\n",
    "    # Fit the model with the given training set\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions for the training and testing sets\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_tr = classifier.predict(X_train)\n",
    "\n",
    "    # ROC curve metrics\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    # Other performance metrics\n",
    "    # Testing\n",
    "    acc.append(accuracy_score(y_test,y_pred))\n",
    "    acc_bal.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    prec.append(precision_score(y_test,y_pred))\n",
    "    rec.append(recall_score(y_test,y_pred, pos_label=1))\n",
    "    spec.append(recall_score(y_test,y_pred, pos_label=0))\n",
    "    AUC_v.append(roc_auc_score(y_test,y_pred))\n",
    "    # Training\n",
    "    acc_tr.append(accuracy_score(y_train,y_pred_tr))\n",
    "    acc_bal_tr.append(balanced_accuracy_score(y_train,y_pred_tr))\n",
    "    prec_tr.append(precision_score(y_train,y_pred_tr))\n",
    "    rec_tr.append(recall_score(y_train,y_pred_tr, pos_label=1))\n",
    "    spec_tr.append(recall_score(y_train,y_pred_tr, pos_label=0))\n",
    "    AUC_v_tr.append(roc_auc_score(y_train,y_pred_tr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dataframe with all the results\n",
    "perf_scores.Train_Acc = acc_tr\n",
    "perf_scores.Train_BalAcc = acc_bal_tr\n",
    "perf_scores.Train_Prec = prec_tr\n",
    "perf_scores.Train_Rec = rec_tr\n",
    "perf_scores.Train_Spec = spec_tr\n",
    "perf_scores.Train_AUC = AUC_v_tr\n",
    "perf_scores.Test_Acc = acc\n",
    "perf_scores.Test_BalAcc\t = acc_bal\n",
    "perf_scores.Test_Prec = prec\n",
    "perf_scores.Test_Rec = rec\n",
    "perf_scores.Test_Spec = spec\n",
    "perf_scores.Test_AUC = AUC_v\n",
    "# Best parameters\n",
    "best_parameters.n_estimators = [best_n_estim]\n",
    "best_parameters.max_depth = [best_max_depth]\n",
    "best_parameters.max_features = [best_max_features]\n",
    "# Data ROC curves\n",
    "data_roc.mean_fpr = mean_fpr\n",
    "for i in range(1,6):\n",
    "    data_roc.iloc[:,i] = tprs[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Train_BalAcc</th>\n",
       "      <th>Train_Prec</th>\n",
       "      <th>Train_Rec</th>\n",
       "      <th>Train_Spec</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Test_BalAcc</th>\n",
       "      <th>Test_Prec</th>\n",
       "      <th>Test_Rec</th>\n",
       "      <th>Test_Spec</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774490</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.717232</td>\n",
       "      <td>0.509368</td>\n",
       "      <td>0.902806</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.690195</td>\n",
       "      <td>0.575670</td>\n",
       "      <td>0.467553</td>\n",
       "      <td>0.292593</td>\n",
       "      <td>0.858747</td>\n",
       "      <td>0.575670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739994</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.623735</td>\n",
       "      <td>0.265424</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.599915</td>\n",
       "      <td>0.764554</td>\n",
       "      <td>0.755793</td>\n",
       "      <td>0.750286</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.823474</td>\n",
       "      <td>0.755793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.671016</td>\n",
       "      <td>0.440912</td>\n",
       "      <td>0.895422</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.794759</td>\n",
       "      <td>0.670632</td>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.393310</td>\n",
       "      <td>0.947953</td>\n",
       "      <td>0.670632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.767956</td>\n",
       "      <td>0.677160</td>\n",
       "      <td>0.730637</td>\n",
       "      <td>0.427837</td>\n",
       "      <td>0.926483</td>\n",
       "      <td>0.677160</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>0.548539</td>\n",
       "      <td>0.528727</td>\n",
       "      <td>0.166953</td>\n",
       "      <td>0.930125</td>\n",
       "      <td>0.548539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.757572</td>\n",
       "      <td>0.670217</td>\n",
       "      <td>0.731356</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>0.925310</td>\n",
       "      <td>0.670217</td>\n",
       "      <td>0.724549</td>\n",
       "      <td>0.611001</td>\n",
       "      <td>0.451533</td>\n",
       "      <td>0.379556</td>\n",
       "      <td>0.842446</td>\n",
       "      <td>0.611001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Acc  Train_BalAcc  Train_Prec  Train_Rec  Train_Spec  Train_AUC  \\\n",
       "0   0.774490      0.706087    0.717232   0.509368    0.902806   0.706087   \n",
       "1   0.739994      0.599915    0.623735   0.265424    0.934407   0.599915   \n",
       "2   0.747231      0.668167    0.671016   0.440912    0.895422   0.668167   \n",
       "3   0.767956      0.677160    0.730637   0.427837    0.926483   0.677160   \n",
       "4   0.757572      0.670217    0.731356   0.415123    0.925310   0.670217   \n",
       "\n",
       "   Test_Acc  Test_BalAcc  Test_Prec  Test_Rec  Test_Spec  Test_AUC  \n",
       "0  0.690195     0.575670   0.467553  0.292593   0.858747  0.575670  \n",
       "1  0.764554     0.755793   0.750286  0.688112   0.823474  0.755793  \n",
       "2  0.794759     0.670632   0.742515  0.393310   0.947953  0.670632  \n",
       "3  0.686276     0.548539   0.528727  0.166953   0.930125  0.548539  \n",
       "4  0.724549     0.611001   0.451533  0.379556   0.842446  0.611001  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 91 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters from random grid search\n",
    "SEED = 10\n",
    "n_estimators = [120, 890, 340, 890]\n",
    "max_depth = [242, 135, 457, 100]\n",
    "max_features = [15, 10, 10, 10]\n",
    "best_n_estim = n_estimators[choose_condition]\n",
    "best_max_depth = max_depth[choose_condition]\n",
    "best_max_features = max_features[choose_condition]\n",
    "\n",
    "# Indices of participants\n",
    "idx_part = list(range(0, 16))\n",
    "idx_label = [0]*8 + [1]*8\n",
    "\n",
    "# Create the k-fold\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# Create the classifier\n",
    "# classifier = RandomForestClassifier(n_estimators=best_n_estim, max_depth=best_max_depth,\n",
    "#                             max_features=best_max_features, n_jobs=-1)\n",
    "# classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "classifier = make_pipeline(StandardScaler(),LinearSVC())\n",
    "\n",
    "# Save performance metrics\n",
    "tprs = []; aucs = []; acc = []; acc_bal = []; prec = []; rec = []; spec = []; AUC_v = []\n",
    "acc_tr = []; acc_bal_tr = []; prec_tr = []; rec_tr = []; spec_tr = []; AUC_v_tr = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Apply cross-validation\n",
    "for _, (train, test) in enumerate(cv.split(idx_part,idx_label)):\n",
    "    train_list = [data_list[index] for index in train]\n",
    "    test_list = [data_list[index] for index in test]\n",
    "    # Read the data from the participants to be used for training and testing\n",
    "    df_data_train = pd.concat(train_list, ignore_index=True)\n",
    "    df_data_test = pd.concat(test_list, ignore_index=True)\n",
    "    # Delete the features that offer extra information from the dataset\n",
    "    df_data_train = df_data_train.drop(features_extra,axis = 1)\n",
    "    df_data_train = df_data_train.drop('time',axis=1)          # Drop the inserted time too\n",
    "    df_data_test = df_data_test.drop(features_extra,axis = 1)\n",
    "    df_data_test = df_data_test.drop('time',axis=1)\n",
    "    \n",
    "    # Check if running on Agave\n",
    "    if(AGAVE==True):\n",
    "        sample_train = df_data_train.sample(frac=1, random_state=SEED);\n",
    "        sample_test = df_data_test.sample(frac=1, random_state=SEED);\n",
    "    else:\n",
    "        sample_train = df_data_train.sample(frac=0.1, random_state=SEED);\n",
    "        sample_test = df_data_test.sample(frac=0.1, random_state=SEED);\n",
    "    \n",
    "    # Scale the data to a range [0,1]\n",
    "    idx_train = np.shape(sample_train)[0]\n",
    "    sample_comb = MinMaxScaler(copy=False).fit_transform(np.concatenate((\n",
    "        sample_train.drop('boolAuto',axis=1).to_numpy(), \n",
    "        sample_test.drop('boolAuto',axis=1).to_numpy()), axis=0))\n",
    "    # Split scaled data into training and testing\n",
    "    X_train = sample_comb[0:idx_train]\n",
    "    y_train = sample_train['boolAuto']\n",
    "    X_test = sample_comb[idx_train:len(sample_comb)]\n",
    "    y_test = sample_test['boolAuto']\n",
    "\n",
    "    # Fit the model with the given training set\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions for the training and testing sets\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_tr = classifier.predict(X_train)\n",
    "\n",
    "    # ROC curve metrics\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    # Other performance metrics\n",
    "    # Testing\n",
    "    acc.append(accuracy_score(y_test,y_pred))\n",
    "    acc_bal.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    prec.append(precision_score(y_test,y_pred))\n",
    "    rec.append(recall_score(y_test,y_pred, pos_label=1))\n",
    "    spec.append(recall_score(y_test,y_pred, pos_label=0))\n",
    "    AUC_v.append(roc_auc_score(y_test,y_pred))\n",
    "    # Training\n",
    "    acc_tr.append(accuracy_score(y_train,y_pred_tr))\n",
    "    acc_bal_tr.append(balanced_accuracy_score(y_train,y_pred_tr))\n",
    "    prec_tr.append(precision_score(y_train,y_pred_tr))\n",
    "    rec_tr.append(recall_score(y_train,y_pred_tr, pos_label=1))\n",
    "    spec_tr.append(recall_score(y_train,y_pred_tr, pos_label=0))\n",
    "    AUC_v_tr.append(roc_auc_score(y_train,y_pred_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25469775865972377"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test==1)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dataframe with all the results\n",
    "perf_scores.Train_Acc = acc_tr\n",
    "perf_scores.Train_BalAcc = acc_bal_tr\n",
    "perf_scores.Train_Prec = prec_tr\n",
    "perf_scores.Train_Rec = rec_tr\n",
    "perf_scores.Train_Spec = spec_tr\n",
    "perf_scores.Train_AUC = AUC_v_tr\n",
    "perf_scores.Test_Acc = acc\n",
    "perf_scores.Test_BalAcc\t = acc_bal\n",
    "perf_scores.Test_Prec = prec\n",
    "perf_scores.Test_Rec = rec\n",
    "perf_scores.Test_Spec = spec\n",
    "perf_scores.Test_AUC = AUC_v\n",
    "# Best parameters\n",
    "best_parameters.n_estimators = [best_n_estim]\n",
    "best_parameters.max_depth = [best_max_depth]\n",
    "best_parameters.max_features = [best_max_features]\n",
    "# Data ROC curves\n",
    "data_roc.mean_fpr = mean_fpr\n",
    "for i in range(1,6):\n",
    "    data_roc.iloc[:,i] = tprs[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Train_BalAcc</th>\n",
       "      <th>Train_Prec</th>\n",
       "      <th>Train_Rec</th>\n",
       "      <th>Train_Spec</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Test_BalAcc</th>\n",
       "      <th>Test_Prec</th>\n",
       "      <th>Test_Rec</th>\n",
       "      <th>Test_Spec</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.824168</td>\n",
       "      <td>0.767775</td>\n",
       "      <td>0.807112</td>\n",
       "      <td>0.605597</td>\n",
       "      <td>0.929953</td>\n",
       "      <td>0.767775</td>\n",
       "      <td>0.715585</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>0.537832</td>\n",
       "      <td>0.317540</td>\n",
       "      <td>0.884325</td>\n",
       "      <td>0.600933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.787151</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.728562</td>\n",
       "      <td>0.426462</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.792253</td>\n",
       "      <td>0.768697</td>\n",
       "      <td>0.901666</td>\n",
       "      <td>0.586713</td>\n",
       "      <td>0.950681</td>\n",
       "      <td>0.768697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794962</td>\n",
       "      <td>0.736629</td>\n",
       "      <td>0.742004</td>\n",
       "      <td>0.568964</td>\n",
       "      <td>0.904294</td>\n",
       "      <td>0.736629</td>\n",
       "      <td>0.684533</td>\n",
       "      <td>0.551781</td>\n",
       "      <td>0.391074</td>\n",
       "      <td>0.255190</td>\n",
       "      <td>0.848371</td>\n",
       "      <td>0.551781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800842</td>\n",
       "      <td>0.730729</td>\n",
       "      <td>0.765734</td>\n",
       "      <td>0.538204</td>\n",
       "      <td>0.923255</td>\n",
       "      <td>0.730729</td>\n",
       "      <td>0.742519</td>\n",
       "      <td>0.646369</td>\n",
       "      <td>0.671577</td>\n",
       "      <td>0.379995</td>\n",
       "      <td>0.912743</td>\n",
       "      <td>0.646369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.802314</td>\n",
       "      <td>0.736912</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.545925</td>\n",
       "      <td>0.927899</td>\n",
       "      <td>0.736912</td>\n",
       "      <td>0.723719</td>\n",
       "      <td>0.658034</td>\n",
       "      <td>0.462605</td>\n",
       "      <td>0.524148</td>\n",
       "      <td>0.791920</td>\n",
       "      <td>0.658034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Acc  Train_BalAcc  Train_Prec  Train_Rec  Train_Spec  Train_AUC  \\\n",
       "0   0.824168      0.767775    0.807112   0.605597    0.929953   0.767775   \n",
       "1   0.787151      0.680687    0.728562   0.426462    0.934911   0.680687   \n",
       "2   0.794962      0.736629    0.742004   0.568964    0.904294   0.736629   \n",
       "3   0.800842      0.730729    0.765734   0.538204    0.923255   0.730729   \n",
       "4   0.802314      0.736912    0.787629   0.545925    0.927899   0.736912   \n",
       "\n",
       "   Test_Acc  Test_BalAcc  Test_Prec  Test_Rec  Test_Spec  Test_AUC  \n",
       "0  0.715585     0.600933   0.537832  0.317540   0.884325  0.600933  \n",
       "1  0.792253     0.768697   0.901666  0.586713   0.950681  0.768697  \n",
       "2  0.684533     0.551781   0.391074  0.255190   0.848371  0.551781  \n",
       "3  0.742519     0.646369   0.671577  0.379995   0.912743  0.646369  \n",
       "4  0.723719     0.658034   0.462605  0.524148   0.791920  0.658034  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b941f43c886fd79c9cadd6d79d1202cd65c517310108e5ac245f0d9f6cd0a3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
