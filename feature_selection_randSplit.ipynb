{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 91 vs 20 features: Classification by Automation Condition (Random Sampling)\n",
    "- Prediction of automation usage using all features and the top 20\n",
    "- We train and test by automation condition\n",
    "    - Grouping the data from all participants in a condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import os as os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose if running on Agave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGAVE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Choose automation condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_condition  = 3\n",
    "conditions = ['SH','SL','FH','FL','ALL']\n",
    "cond = conditions[choose_condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path to all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "if(AGAVE==True):\n",
    "    files_path = '../../../NewFeatures/' + cond             # Agave\n",
    "else:\n",
    "    files_path = '../../../features_data_risk/' + cond      # Local\n",
    "\n",
    "all_files = glob.glob(os.path.join(files_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that offer extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that offer extra information (they're basically the same as boolAuto)\n",
    "features_extra = ['boolHand','boolTake','brakeOshp','sumAuto','sumHand','sumTake','sumTogg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that are related to the operator's actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions\n",
    "features_internal = ['accAngOshpX','accAngOshpY','accAngOshpZ','accLinOshpX',\n",
    "\t\t\t\t\t'accLinOshpY','accLinOshpZ','boolButnA','boolButnB',\n",
    "\t\t\t\t\t'boolViolButn','boolViolLane','boolViolLead','boolViolPeds',\n",
    "\t\t\t\t\t'boolViolRang','boolViolTraf','boolViolVehs',\n",
    "\t\t\t\t\t'oriOshpX','oriOshpY','oriOshpZ','psnOshpLane','psnOshpLaneAbs',\n",
    "\t\t\t\t\t'psnOshpLaneLft','psnOshpX','psnOshpY','psnOshpZ',\n",
    "\t\t\t\t\t'steerOshp','sumViolButn','sumViolLane','sumViolLead','sumViolPeds',\n",
    "\t\t\t\t\t'sumViolRang','sumViolTraf','sumViolVehs','throtOshp','timeReact',\n",
    "\t\t\t\t\t'velAngOshpX','velAngOshpY','velAngOshpZ','velLinOshp','velLinOshpLane',\n",
    "\t\t\t\t\t'velLinOshpLaneAbs','velLinOshpLaneLft','velLinOshpRang','velLinOshpX',\n",
    "\t\t\t\t\t'velLinOshpY','velLinOshpZ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process data\n",
    "# Assign features from current time-step to future use of automation,\n",
    "# The idea is to predict future use of automation based on current behavior\n",
    "delay = 1/60            # How much time in advance we want to predict automation usage (in seconds)\n",
    "h = (int)(delay*60 - 1) # Turn the time into index (Considering a sampling rate of 60 Hz)\n",
    "data_list = []\n",
    "for file in all_files:\n",
    "    data_participant = pd.read_csv(file)\n",
    "    data_participant.insert(0,\"time\",[(i*1/60) for i in range(0,data_participant.shape[0])],True)\n",
    "    data_auto = data_participant['boolAuto']\n",
    "    data_auto = np.array(data_auto.iloc[h:])\n",
    "    data_participant = data_participant.drop('boolAuto', axis=1)\n",
    "    data_participant = data_participant.head(data_participant.shape[0]-h)\n",
    "    data_participant.insert(data_participant.shape[1],\"boolAuto\",data_auto,True)\n",
    "    data_list.append(data_participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the data from all participants together\n",
    "df_data = pd.concat(data_list, ignore_index=True) # Read the data from all participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete features that offer extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the features that offer extra information from the dataset\n",
    "# The idea is to determine which features are more related to automation usage\n",
    "df_data = df_data.drop(features_extra,axis = 1)\n",
    "df_data = df_data.drop('time',axis=1)               # Drop the inserted time too\n",
    "# df_data = df_data.drop(features_internal,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take just a sample of the data for speed\n",
    "# Change this when running on Agave\n",
    "SEED = 10\n",
    "if(AGAVE==True):\n",
    "    sample_data = df_data.sample(frac=1, random_state=SEED);\n",
    "else:\n",
    "    sample_data = df_data.sample(frac=0.1, random_state=SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = sample_data.drop('boolAuto',axis = 1)\n",
    "y_data = sample_data['boolAuto']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "SH_feats = ['psnOshpRang'    ,\n",
    "'score'          ,\n",
    "'velLinOshpX'    ,\n",
    "'velLinOshp'     ,\n",
    "'rrisk'          ,\n",
    "'sumViolLane'    ,\n",
    "'velLinLead'     ,\n",
    "'throtOshp'      ,\n",
    "'sumViolRang'    ,\n",
    "'odomRoad'       ,\n",
    "'velLinOshpRang' ,\n",
    "'sumViolPeds'    ,\n",
    "'ttcLead'        ,\n",
    "'sumViolButn'    ,\n",
    "'accLinOshpX'    ,\n",
    "'psnTrafPrxY'    ,\n",
    "'psnTrafPrxX'    ,\n",
    "'boolStatRang'   ,\n",
    "'oriTrafPrxZ'    ,\n",
    "'oriOshpY'       ]\n",
    "\n",
    "SL_feats = ['psnOshpRang'    ,\n",
    "'rrisk'          ,\n",
    "'sumViolAwrd'    ,\n",
    "'velLinOshp'     ,\n",
    "'throtOshp'      ,\n",
    "'velLinOshpX'    ,\n",
    "'sumViolRang'    ,\n",
    "'score'          ,\n",
    "'accLinOshpX'    ,\n",
    "'sumViolButn'    ,\n",
    "'oriOshpY'       ,\n",
    "'velLinLead'     ,\n",
    "'odomRoad'       ,\n",
    "'sumViolLane'    ,\n",
    "'velLinOshpRang' ,\n",
    "'psnTrafPrxX'    ,\n",
    "'psnTrafPrxY'    ,\n",
    "'accAngOshpY'    ,\n",
    "'oriLeadZ'       ,\n",
    "'velAngOshpY'    ]\n",
    "\n",
    "FH_feats = ['velLinOshpX'    ,\n",
    "'psnOshpRang'    ,\n",
    "'score'          ,\n",
    "'rrisk'          ,\n",
    "'velLinOshp'     ,\n",
    "'throtOshp'      ,\n",
    "'sumViolRang'    ,\n",
    "'velLinLead'     ,\n",
    "'odomRoad'       ,\n",
    "'sumViolButn'    ,\n",
    "'sumViolLane'    ,\n",
    "'accLinOshpX'    ,\n",
    "'velLinOshpRang' ,\n",
    "'psnOshpLaneLft' ,\n",
    "'oriTrafPrxZ'    ,\n",
    "'velAngLeadZAbs' ,\n",
    "'psnTrafPrxX'    ,\n",
    "'oriOshpY'       ,\n",
    "'psnTrafPrxY'    ,\n",
    "'oriOshpZ'       ]\n",
    "\n",
    "FL_feats = ['psnOshpRang' ,\n",
    "'sumViolAwrd' ,\n",
    "'velLinOshpX' ,\n",
    "'rrisk'       ,\n",
    "'throtOshp'   ,\n",
    "'velLinOshp'  ,\n",
    "'sumViolLane' ,\n",
    "'score'       ,\n",
    "'accLinOshpX' ,\n",
    "'odomRoad'    ,\n",
    "'sumViolRang' ,\n",
    "'oriTrafPrxZ' ,\n",
    "'sumViolButn' ,\n",
    "'psnTrafPrxX' ,\n",
    "'velLinLead'  ,\n",
    "'sumViolPeds' ,\n",
    "'psnLeadY'    ,\n",
    "'timeReact'   ,\n",
    "'psnTrafPrxY' ,\n",
    "'psnRoadY'    ]\n",
    "\n",
    "top_features_all = [SH_feats,SL_feats,FH_feats,FL_feats]\n",
    "top_feat_cond = top_features_all[choose_condition]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataset to consider only the top num_feats features\n",
    "X_data_cut = X_data[top_feat_cond]\n",
    "# Scale the data (0,1)\n",
    "X_data_cut = MinMaxScaler().fit_transform(X_data_cut)\n",
    "y_data_cut = np.array(y_data.to_list())\n",
    "# X_data = X_data[top_feat_cond]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "frac = 0.8 # Choose fraction of data to use for training\n",
    "n_samples = len(X_data_cut)\n",
    "idx_split = (int)(np.round(frac*n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "train_labels = np.array(y_data_cut[0:idx_split])\n",
    "test_labels = np.array(y_data_cut[idx_split:n_samples]) \n",
    "train_features = np.array(X_data_cut[0:idx_split,:])\n",
    "test_features = np.array(X_data_cut[idx_split:n_samples,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (55266, 20)\n",
      "Testing Data Shape: (13816, 20)\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print('Training Data Shape:', train_features.shape)\n",
    "print('Testing Data Shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the performance results\n",
    "data_scores = {'Train_Acc':[],'Train_BalAcc':[],'Train_Prec':[],'Train_Rec':[],'Train_Spec':[],\n",
    "                'Train_AUC':[],'Test_Acc':[],'Test_BalAcc':[],'Test_Prec':[],'Test_Rec':[],\n",
    "                'Test_Spec':[],'Test_AUC':[]}\n",
    "perf_scores = pd.DataFrame(data=data_scores)\n",
    "# Save the ROC curve data\n",
    "data_roc = pd.DataFrame({'mean_fpr':[], 'tpr_1':[], 'tpr_2':[], 'tpr_3':[], 'tpr_4':[], \n",
    "                        'tpr_5':[]}) # 5 KFold\n",
    "# Save the best set of parameter for the model\n",
    "best_parameters = pd.DataFrame({'n_estimators':[], 'max_depth':[], 'max_features':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation (5-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation when the best parameters have been selected\n",
    "best_n_estim = 120\n",
    "best_max_depth = 5157\n",
    "best_max_features = 5\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "classifier = make_pipeline(StandardScaler(),LinearSVC())\n",
    "\n",
    "tprs = []; aucs = []; acc = []; acc_bal = []; prec = []; rec = []; spec = []; AUC_v = []\n",
    "acc_tr = []; acc_bal_tr = []; prec_tr = []; rec_tr = []; spec_tr = []; AUC_v_tr = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X_data_cut, y_data_cut)):\n",
    "    # Classifier training and testing\n",
    "    y_train = y_data_cut[train]\n",
    "    classifier.fit(X_data_cut[train], y_train)\n",
    "    y_test = y_data_cut[test]\n",
    "    y_pred = classifier.predict(X_data_cut[test])\n",
    "    y_pred_tr = classifier.predict(X_data_cut[train])\n",
    "\n",
    "    # ROC curve metrics\n",
    "    fpr, tpr, _ = roc_curve(y_data_cut[test], y_pred, pos_label=1)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    # Other performance metrics\n",
    "    # Testing\n",
    "    acc.append(accuracy_score(y_test,y_pred))\n",
    "    acc_bal.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    prec.append(precision_score(y_test,y_pred))\n",
    "    rec.append(recall_score(y_test,y_pred, pos_label=1))\n",
    "    spec.append(recall_score(y_test,y_pred, pos_label=0))\n",
    "    AUC_v.append(roc_auc_score(y_test,y_pred))\n",
    "    # Training\n",
    "    acc_tr.append(accuracy_score(y_train,y_pred_tr))\n",
    "    acc_bal_tr.append(balanced_accuracy_score(y_train,y_pred_tr))\n",
    "    prec_tr.append(precision_score(y_train,y_pred_tr))\n",
    "    rec_tr.append(recall_score(y_train,y_pred_tr, pos_label=1))\n",
    "    spec_tr.append(recall_score(y_train,y_pred_tr, pos_label=0))\n",
    "    AUC_v_tr.append(roc_auc_score(y_train,y_pred_tr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dataframe with all the results\n",
    "perf_scores.Train_Acc = acc_tr\n",
    "perf_scores.Train_BalAcc = acc_bal_tr\n",
    "perf_scores.Train_Prec = prec_tr\n",
    "perf_scores.Train_Rec = rec_tr\n",
    "perf_scores.Train_Spec = spec_tr\n",
    "perf_scores.Train_AUC = AUC_v_tr\n",
    "perf_scores.Test_Acc = acc\n",
    "perf_scores.Test_BalAcc\t = acc_bal\n",
    "perf_scores.Test_Prec = prec\n",
    "perf_scores.Test_Rec = rec\n",
    "perf_scores.Test_Spec = spec\n",
    "perf_scores.Test_AUC = AUC_v\n",
    "# Best parameters\n",
    "best_parameters.n_estimators = [best_n_estim]\n",
    "best_parameters.max_depth = [best_max_depth]\n",
    "best_parameters.max_features = [best_max_features]\n",
    "# Data ROC curves\n",
    "data_roc.mean_fpr = mean_fpr\n",
    "for i in range(1,6):\n",
    "    data_roc.iloc[:,i] = tprs[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Train_BalAcc</th>\n",
       "      <th>Train_Prec</th>\n",
       "      <th>Train_Rec</th>\n",
       "      <th>Train_Spec</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Test_BalAcc</th>\n",
       "      <th>Test_Prec</th>\n",
       "      <th>Test_Rec</th>\n",
       "      <th>Test_Spec</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754221</td>\n",
       "      <td>0.653617</td>\n",
       "      <td>0.703143</td>\n",
       "      <td>0.381357</td>\n",
       "      <td>0.925878</td>\n",
       "      <td>0.653617</td>\n",
       "      <td>0.757038</td>\n",
       "      <td>0.655175</td>\n",
       "      <td>0.716515</td>\n",
       "      <td>0.379477</td>\n",
       "      <td>0.930874</td>\n",
       "      <td>0.655175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.754202</td>\n",
       "      <td>0.653728</td>\n",
       "      <td>0.702726</td>\n",
       "      <td>0.381816</td>\n",
       "      <td>0.925640</td>\n",
       "      <td>0.653728</td>\n",
       "      <td>0.757038</td>\n",
       "      <td>0.658148</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.390496</td>\n",
       "      <td>0.925801</td>\n",
       "      <td>0.658148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.754279</td>\n",
       "      <td>0.653907</td>\n",
       "      <td>0.702754</td>\n",
       "      <td>0.382253</td>\n",
       "      <td>0.925561</td>\n",
       "      <td>0.653907</td>\n",
       "      <td>0.754632</td>\n",
       "      <td>0.654166</td>\n",
       "      <td>0.704017</td>\n",
       "      <td>0.382319</td>\n",
       "      <td>0.926012</td>\n",
       "      <td>0.654166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.754786</td>\n",
       "      <td>0.656337</td>\n",
       "      <td>0.699228</td>\n",
       "      <td>0.389887</td>\n",
       "      <td>0.922786</td>\n",
       "      <td>0.656337</td>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.647680</td>\n",
       "      <td>0.687817</td>\n",
       "      <td>0.373364</td>\n",
       "      <td>0.921996</td>\n",
       "      <td>0.647680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755890</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.704335</td>\n",
       "      <td>0.388876</td>\n",
       "      <td>0.924849</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.755284</td>\n",
       "      <td>0.658362</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.396006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.658362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Acc  Train_BalAcc  Train_Prec  Train_Rec  Train_Spec  Train_AUC  \\\n",
       "0   0.754221      0.653617    0.703143   0.381357    0.925878   0.653617   \n",
       "1   0.754202      0.653728    0.702726   0.381816    0.925640   0.653728   \n",
       "2   0.754279      0.653907    0.702754   0.382253    0.925561   0.653907   \n",
       "3   0.754786      0.656337    0.699228   0.389887    0.922786   0.656337   \n",
       "4   0.755890      0.656863    0.704335   0.388876    0.924849   0.656863   \n",
       "\n",
       "   Test_Acc  Test_BalAcc  Test_Prec  Test_Rec  Test_Spec  Test_AUC  \n",
       "0  0.757038     0.655175   0.716515  0.379477   0.930874  0.655175  \n",
       "1  0.757038     0.658148   0.707865  0.390496   0.925801  0.658148  \n",
       "2  0.754632     0.654166   0.704017  0.382319   0.926012  0.654166  \n",
       "3  0.749059     0.647680   0.687817  0.373364   0.921996  0.647680  \n",
       "4  0.755284     0.658362   0.696970  0.396006   0.920719  0.658362  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 91 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataset to consider only all the features\n",
    "X_data_all = X_data\n",
    "# Scale the data (0,1)\n",
    "X_data_all = MinMaxScaler().fit_transform(X_data_all)\n",
    "y_data_all = np.array(y_data.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "frac = 0.8 # Choose fraction of data to use for training\n",
    "n_samples = len(X_data_all)\n",
    "idx_split = (int)(np.round(frac*n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "train_labels = np.array(y_data_all[0:idx_split])\n",
    "test_labels = np.array(y_data_all[idx_split:n_samples]) \n",
    "train_features = np.array(X_data_all[0:idx_split,:])\n",
    "test_features = np.array(X_data_all[idx_split:n_samples,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (55266, 91)\n",
      "Testing Data Shape: (13816, 91)\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print('Training Data Shape:', train_features.shape)\n",
    "print('Testing Data Shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\cbust\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation when the best parameters have been selected\n",
    "best_n_estim = 120\n",
    "best_max_depth = 5157\n",
    "best_max_features = 5\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "classifier = make_pipeline(StandardScaler(),LinearSVC())\n",
    "\n",
    "tprs = []; aucs = []; acc = []; acc_bal = []; prec = []; rec = []; spec = []; AUC_v = []\n",
    "acc_tr = []; acc_bal_tr = []; prec_tr = []; rec_tr = []; spec_tr = []; AUC_v_tr = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X_data_all, y_data_all)):\n",
    "    # Classifier training and testing\n",
    "    y_train = y_data_all[train]\n",
    "    classifier.fit(X_data_all[train], y_train)\n",
    "    y_test = y_data_all[test]\n",
    "    y_pred = classifier.predict(X_data_all[test])\n",
    "    y_pred_tr = classifier.predict(X_data_all[train])\n",
    "\n",
    "    # ROC curve metrics\n",
    "    fpr, tpr, _ = roc_curve(y_data_all[test], y_pred, pos_label=1)\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "\n",
    "    # Other performance metrics\n",
    "    # Testing\n",
    "    acc.append(accuracy_score(y_test,y_pred))\n",
    "    acc_bal.append(balanced_accuracy_score(y_test,y_pred))\n",
    "    prec.append(precision_score(y_test,y_pred))\n",
    "    rec.append(recall_score(y_test,y_pred, pos_label=1))\n",
    "    spec.append(recall_score(y_test,y_pred, pos_label=0))\n",
    "    AUC_v.append(roc_auc_score(y_test,y_pred))\n",
    "    # Training\n",
    "    acc_tr.append(accuracy_score(y_train,y_pred_tr))\n",
    "    acc_bal_tr.append(balanced_accuracy_score(y_train,y_pred_tr))\n",
    "    prec_tr.append(precision_score(y_train,y_pred_tr))\n",
    "    rec_tr.append(recall_score(y_train,y_pred_tr, pos_label=1))\n",
    "    spec_tr.append(recall_score(y_train,y_pred_tr, pos_label=0))\n",
    "    AUC_v_tr.append(roc_auc_score(y_train,y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dataframe with all the results\n",
    "perf_scores.Train_Acc = acc_tr\n",
    "perf_scores.Train_BalAcc = acc_bal_tr\n",
    "perf_scores.Train_Prec = prec_tr\n",
    "perf_scores.Train_Rec = rec_tr\n",
    "perf_scores.Train_Spec = spec_tr\n",
    "perf_scores.Train_AUC = AUC_v_tr\n",
    "perf_scores.Test_Acc = acc\n",
    "perf_scores.Test_BalAcc\t = acc_bal\n",
    "perf_scores.Test_Prec = prec\n",
    "perf_scores.Test_Rec = rec\n",
    "perf_scores.Test_Spec = spec\n",
    "perf_scores.Test_AUC = AUC_v\n",
    "# Best parameters\n",
    "best_parameters.n_estimators = [best_n_estim]\n",
    "best_parameters.max_depth = [best_max_depth]\n",
    "best_parameters.max_features = [best_max_features]\n",
    "# Data ROC curves\n",
    "data_roc.mean_fpr = mean_fpr\n",
    "for i in range(1,6):\n",
    "    data_roc.iloc[:,i] = tprs[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Acc</th>\n",
       "      <th>Train_BalAcc</th>\n",
       "      <th>Train_Prec</th>\n",
       "      <th>Train_Rec</th>\n",
       "      <th>Train_Spec</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Test_BalAcc</th>\n",
       "      <th>Test_Prec</th>\n",
       "      <th>Test_Rec</th>\n",
       "      <th>Test_Spec</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.795513</td>\n",
       "      <td>0.717112</td>\n",
       "      <td>0.766757</td>\n",
       "      <td>0.504936</td>\n",
       "      <td>0.929287</td>\n",
       "      <td>0.717112</td>\n",
       "      <td>0.796844</td>\n",
       "      <td>0.717501</td>\n",
       "      <td>0.773578</td>\n",
       "      <td>0.502755</td>\n",
       "      <td>0.932248</td>\n",
       "      <td>0.717501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794662</td>\n",
       "      <td>0.715763</td>\n",
       "      <td>0.765797</td>\n",
       "      <td>0.502239</td>\n",
       "      <td>0.929287</td>\n",
       "      <td>0.715763</td>\n",
       "      <td>0.795759</td>\n",
       "      <td>0.717080</td>\n",
       "      <td>0.768369</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.930029</td>\n",
       "      <td>0.717080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794032</td>\n",
       "      <td>0.716290</td>\n",
       "      <td>0.760614</td>\n",
       "      <td>0.505883</td>\n",
       "      <td>0.926697</td>\n",
       "      <td>0.716290</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.717306</td>\n",
       "      <td>0.768719</td>\n",
       "      <td>0.504478</td>\n",
       "      <td>0.930134</td>\n",
       "      <td>0.717306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.795299</td>\n",
       "      <td>0.719027</td>\n",
       "      <td>0.759956</td>\n",
       "      <td>0.512598</td>\n",
       "      <td>0.925455</td>\n",
       "      <td>0.719027</td>\n",
       "      <td>0.792270</td>\n",
       "      <td>0.713681</td>\n",
       "      <td>0.757902</td>\n",
       "      <td>0.501033</td>\n",
       "      <td>0.926329</td>\n",
       "      <td>0.713681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796457</td>\n",
       "      <td>0.719069</td>\n",
       "      <td>0.766422</td>\n",
       "      <td>0.509643</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.719069</td>\n",
       "      <td>0.793935</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>0.753955</td>\n",
       "      <td>0.514233</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.718480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Acc  Train_BalAcc  Train_Prec  Train_Rec  Train_Spec  Train_AUC  \\\n",
       "0   0.795513      0.717112    0.766757   0.504936    0.929287   0.717112   \n",
       "1   0.794662      0.715763    0.765797   0.502239    0.929287   0.715763   \n",
       "2   0.794032      0.716290    0.760614   0.505883    0.926697   0.716290   \n",
       "3   0.795299      0.719027    0.759956   0.512598    0.925455   0.719027   \n",
       "4   0.796457      0.719069    0.766422   0.509643    0.928496   0.719069   \n",
       "\n",
       "   Test_Acc  Test_BalAcc  Test_Prec  Test_Rec  Test_Spec  Test_AUC  \n",
       "0  0.796844     0.717501   0.773578  0.502755   0.932248  0.717501  \n",
       "1  0.795759     0.717080   0.768369  0.504132   0.930029  0.717080  \n",
       "2  0.795961     0.717306   0.768719  0.504478   0.930134  0.717306  \n",
       "3  0.792270     0.713681   0.757902  0.501033   0.926329  0.713681  \n",
       "4  0.793935     0.718480   0.753955  0.514233   0.922727  0.718480  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b941f43c886fd79c9cadd6d79d1202cd65c517310108e5ac245f0d9f6cd0a3e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
